# SomosNLP Hackathon 2025 - GastronomÃ­a Hispana

Proyecto de fine-tuning de modelos de lenguaje especializados en gastronomÃ­a hispana utilizando tÃ©cnicas de QLoRA y DPO (Direct Preference Optimization).

## DescripciÃ³n del Proyecto

Este proyecto desarrolla modelos de lenguaje especializados en recetas y cultura gastronÃ³mica hispana, con enfoque particular en la cocina ecuatoriana y colombiana. Utiliza tÃ©cnicas avanzadas de fine-tuning como QLoRA y DPO para crear asistentes culinarios que comprenden tanto las tÃ©cnicas de cocina como el contexto cultural de los platos tradicionales.

## Estructura del Proyecto

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ dpo.ipynb              # Entrenamiento con DPO (Direct Preference Optimization)
â”‚   â””â”€â”€ qlora.ipynb            # Fine-tuning con QLoRA
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ analyze_dataset.py      # AnÃ¡lisis y filtrado de datasets por longitud de tokens
â”‚   â”œâ”€â”€ convert_json_to_parquet.py  # ConversiÃ³n de JSON a formato Parquet
â”‚   â”œâ”€â”€ dataset-cohere-dpo.py  # GeneraciÃ³n de datasets DPO con Cohere API
â”‚   â”œâ”€â”€ esbieta.py             # Scraper de recetas de recetasdesbieta.com
â”‚   â”œâ”€â”€ question_bank.py       # GeneraciÃ³n de preguntas sobre recetas
â”‚   â”œâ”€â”€ youtube_count.py       # ExtracciÃ³n de estadÃ­sticas de videos de YouTube
â”‚   â””â”€â”€ yt_transcript.py       # ExtracciÃ³n de transcripciones de YouTube
â””â”€â”€ README.md
```

## ConfiguraciÃ³n Inicial

### Prerrequisitos

- Python 3.8+
- CUDA compatible GPU (recomendado para entrenamiento)
- Tokens de API:
  - Cohere API key
  - Hugging Face token
  - Weights & Biases account (opcional)


## ğŸ“Š Datos y Datasets

### Fuentes de Datos

- **Recetas web**: Scraping automatizado de sitios especializados
- **Videos de YouTube**: Transcripciones y metadatos de videos culinarios
- **Preguntas generadas**: Banco de preguntas educativas sobre recetas

### Datasets Generados

- `patrimonio-gastronomico-hispano`: Dataset principal de recetas
- `gastronomia-hispana-dpo`: Dataset de pares de preferencias para DPO

## ğŸ¤– Entrenamiento de Modelos

### QLoRA Fine-tuning

**Notebook**: `notebooks/qlora.ipynb`

Entrenamiento supervisado para generar respuestas sobre recetas tradicionales:

```python
# ConfiguraciÃ³n del modelo base
MODEL_BASE = "unsloth/mistral-7b-instruct-v0.3-bnb-4bit"
MAX_SEQ_LENGTH = 4096

# ParÃ¡metros de LoRA
LORA_R = 32
LORA_ALPHA = 32
LEARNING_RATE = 2e-4
```

**CaracterÃ­sticas**:
- âœ… OptimizaciÃ³n de memoria con cuantizaciÃ³n 4-bit
- âœ… Template ChatML para conversaciones
- âœ… EvaluaciÃ³n continua durante entrenamiento
- âœ… Guardado automÃ¡tico de checkpoints

### DPO Training

**Notebook**: `notebooks/dpo.ipynb`

OptimizaciÃ³n de preferencias para mejorar la calidad de respuestas:

```python
# ConfiguraciÃ³n DPO
MODEL_BASE = "unsloth/Qwen3-8B-unsloth-bnb-4bit"
BETA = 0.8  # ParÃ¡metro de control de preferencias
LEARNING_RATE = 2e-7
```

**CaracterÃ­sticas**:
- âœ… Entrenamiento con pares chosen/rejected
- âœ… Control fino de preferencias culturales
- âœ… ValidaciÃ³n de calidad de respuestas
- âœ… MÃ©tricas de evaluaciÃ³n especializadas

## ğŸ› ï¸ Scripts de Utilidad

### RecolecciÃ³n de Datos

```bash
# Scraping de recetas
python scripts/esbieta.py --output recetas.json --max-recipes 1000

# ExtracciÃ³n de transcripciones de YouTube
python scripts/yt_transcript.py

# ObtenciÃ³n de estadÃ­sticas de videos
python scripts/youtube_count.py
```

### GeneraciÃ³n de Datasets

```bash
# Generar banco de preguntas
python scripts/question_bank.py

# Crear dataset DPO
python scripts/dataset-cohere-dpo.py

# Convertir formatos
python scripts/convert_json_to_parquet.py
```

### AnÃ¡lisis de Datos

```bash
# Analizar longitud de secuencias
python scripts/analyze_dataset.py
```

## ğŸ“ˆ Modelos Entrenados

### Mistral-7B GastronomÃ­a Hispana
- **Base**: Mistral-7B-Instruct-v0.3
- **EspecializaciÃ³n**: Recetas ecuatorianas y colombianas
- **TÃ©cnica**: QLoRA fine-tuning
- **Formato**: ChatML

### Qwen3-8B GastronomÃ­a Hispana
- **Base**: Qwen3-8B
- **EspecializaciÃ³n**: OptimizaciÃ³n de preferencias culinarias
- **TÃ©cnica**: DPO training
- **Formato**: ChatML

## ğŸ­ CaracterÃ­sticas de los Modelos

### Capacidades Especializadas

- **Conocimiento Cultural**: Comprende el contexto histÃ³rico y regional de los platos
- **TÃ©cnicas Culinarias**: Explica mÃ©todos de cocciÃ³n tradicionales y modernos
- **Ingredientes Locales**: Conoce ingredientes especÃ­ficos de cada regiÃ³n
- **AdaptaciÃ³n de Porciones**: Ajusta recetas segÃºn el nÃºmero de comensales
- **SoluciÃ³n de Problemas**: Ayuda a resolver errores comunes en la cocina

### Formatos Soportados

- **ConversaciÃ³n Natural**: InteracciÃ³n fluida en espaÃ±ol
- **Recetas Paso a Paso**: Instrucciones detalladas y claras
- **Consejos TÃ©cnicos**: Tips profesionales de cocina
- **Contexto Cultural**: Historia y tradiciones gastronÃ³micas

## EvaluaciÃ³n y MÃ©tricas

### MÃ©tricas de Entrenamiento

- **Loss de Entrenamiento**: Monitoreado con Weights & Biases
- **Perplexity**: Medida de fluidez del modelo
- **BLEU Score**: Calidad de generaciÃ³n de texto
- **ValidaciÃ³n Cultural**: RevisiÃ³n manual de autenticidad

### Pruebas de Calidad

```python
# Ejemplo de evaluaciÃ³n
messages = [
    {"role": "user", "content": "Â¿CÃ³mo preparar encebollado ecuatoriano?"}
]

# El modelo debe responder con:
# - Ingredientes especÃ­ficos del plato
# - TÃ©cnicas tradicionales
# - Contexto cultural apropiado
# - Instrucciones claras y precisas
```

## ğŸ“Š Resultados y Benchmarks

### MÃ©tricas de Rendimiento

| Modelo | ParÃ¡metros | VRAM Utilizada | Tiempo Entrenamiento |
|--------|------------|----------------|---------------------|
| Mistral-7B | 7B | ~16GB | ~2 horas |
| Qwen3-8B | 8B | ~18GB | ~3 horas |

### Casos de Uso

- âœ… **Asistente Culinario**: Respuestas sobre recetas tradicionales
- âœ… **EducaciÃ³n GastronÃ³mica**: EnseÃ±anza de tÃ©cnicas y cultura
- âœ… **PreservaciÃ³n Cultural**: DocumentaciÃ³n de tradiciones culinarias
- âœ… **AdaptaciÃ³n Regional**: PersonalizaciÃ³n segÃºn ubicaciÃ³n geogrÃ¡fica

## ğŸ¤ Contribuciones

### CÃ³mo Contribuir

1. **Fork el repositorio**
2. **Crear una rama de feature**: `git checkout -b feature/nueva-funcionalidad`
3. **Commit cambios**: `git commit -am 'Agregar nueva funcionalidad'`
4. **Push a la rama**: `git push origin feature/nueva-funcionalidad`
5. **Crear Pull Request**

### Ãreas de ContribuciÃ³n

- ğŸ³ **Nuevas Recetas**: Ampliar la base de datos con mÃ¡s platos regionales
- ğŸŒ **Nuevas Regiones**: Incluir gastronomÃ­a de otros paÃ­ses hispanos
- ğŸ¤– **Mejoras de Modelo**: Optimizaciones en arquitectura y entrenamiento
- ğŸ“± **Interfaces**: Desarrollo de aplicaciones y demos interactivas

## ğŸ“œ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- **SomosNLP**: Por organizar el hackathon y proporcionar la plataforma
- **Unsloth**: Por las optimizaciones de entrenamiento eficiente
- **Cohere**: Por proporcionar acceso a su API para generaciÃ³n de datos
- **Comunidad Open Source**: Por las herramientas y librerÃ­as utilizadas

## Contacto

- **Equipo**: somosnlp-hackathon-2025
- **Repository**: [GitHub](https://github.com/somosnlp-hackathon-2025)
- **Modelos**: [Hugging Face](https://huggingface.co/somosnlp-hackathon-2025)

---

**Â¡Preservemos y compartamos la riqueza de la gastronomÃ­a hispana a travÃ©s de la inteligencia artificial!** ğŸ‡ªğŸ‡¨ ğŸ¥˜